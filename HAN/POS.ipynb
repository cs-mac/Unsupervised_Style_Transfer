{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "POS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlEngB-mvvcK"
      },
      "source": [
        "# function ClickConnect(){\n",
        "#     console.log(\"Working\");\n",
        "#     document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n",
        "# }\n",
        "# setInterval(ClickConnect, 30000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxwPsrzMYYmf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Veo9iHxjYajt"
      },
      "source": [
        "cd drive/\"My Drive\"/\"Colab Notebooks\"/master_project/HAN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhoS2SjijHi6"
      },
      "source": [
        "%%capture\n",
        "!pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svDDvMhYgxwM",
        "trusted": true,
        "_uuid": "1642a59f5e4d475a1757b74cf74fc4f48f5cecc3"
      },
      "source": [
        "import pandas as pd\n",
        "import tqdm\n",
        "import pickle\n",
        "import sys\n",
        "import time\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "from timeit import default_timer as timer\n",
        "sys.path.append('..')\n",
        "from utilities import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iphJED4Qgxw8",
        "_uuid": "da31e0150178690c03f71da4f77c1883a4639cb3"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXW31PQx5_LU"
      },
      "source": [
        "df_all = pd.read_pickle('df_all.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RDi4LGLi490"
      },
      "source": [
        "df_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkrhdni_UMZz",
        "outputId": "a0fb85ae-bc16-47bb-ef0c-fe0d36522b92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "# POS-tagging\n",
        "tagger = SequenceTagger.load('pos')\n",
        "\n",
        "def get_pos(sentence):\n",
        "    sent_obj = Sentence(sentence)\n",
        "    tagger.predict(sent_obj)\n",
        "    return \" \".join([ptag.tag for ptag in sent_obj.get_spans('pos')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-24 20:28:53,098 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4/POS-ontonotes--h256-l1-b32-p3-0.5-%2Bglove%2Bnews-forward%2Bnews-backward-normal-locked0.5-word0.05--v0.4_0/en-pos-ontonotes-v0.4.pt not found in cache, downloading to /tmp/tmpd7mnzxgd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 432218302/432218302 [00:26<00:00, 16227892.07B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-24 20:29:20,465 copying /tmp/tmpd7mnzxgd to cache at /root/.flair/models/en-pos-ontonotes-v0.4.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-24 20:29:21,627 removing temp file /tmp/tmpd7mnzxgd\n",
            "2020-04-24 20:29:21,877 loading file /root/.flair/models/en-pos-ontonotes-v0.4.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWxFBRsd0jBp"
      },
      "source": [
        "to_pos = df_all[\"words\"].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeafVzboykxS"
      },
      "source": [
        "with open('progress_dict_old.pickle', 'rb') as handle:\n",
        "    progress_dict_old = pickle.load(handle) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC-kw__z1g4h",
        "outputId": "ba5f701f-5bd6-48b7-dacc-6b5e181e683e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "try:\n",
        "    with open('progress_dict.pickle', 'rb') as handle:\n",
        "        progress_dict = pickle.load(handle) \n",
        "    print(\"Loaded Existing Progress Dict\")\n",
        "except FileNotFoundError as e:\n",
        "    print(\"Created New Progress Dict\")\n",
        "    progress_dict = {}\n",
        "    with open('progress_dict.pickle', 'wb') as handle:\n",
        "        pickle.dump(progress_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "while len(progress_dict) != len(set(df_all.words)):\n",
        "    start = timer()\n",
        "    print(\"Opening File...\")\n",
        "    with open('progress_dict.pickle', 'rb') as handle:\n",
        "        progress_dict = pickle.load(handle)    \n",
        "    to_pos = df_all[\"words\"].to_list()[len(progress_dict):]\n",
        "    print(f\"Start taggging, left in queue: {len(to_pos)}\")\n",
        "    for idx, sentence in enumerate(to_pos):\n",
        "        try:\n",
        "            existing_pos = progress_dict_old[sentence]\n",
        "            progress_dict[sentence] = existing_pos\n",
        "        except KeyError as e:\n",
        "            progress_dict[sentence] = get_pos(sentence)\n",
        "        if idx in [5000, 10000, 15000, 20000]:\n",
        "            print(f\":: At step {idx}\")\n",
        "        if idx == 25000:\n",
        "            break\n",
        "    print(\"Saving File...\")\n",
        "    with open('progress_dict.pickle', 'wb') as handle:\n",
        "        pickle.dump(progress_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    time.sleep(5)\n",
        "    print(f\"Minutes: {round((timer() - start)/60, 2)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded Existing Progress Dict\n",
            "Created New Progress Dict\n",
            "Opening File...\n",
            "Start taggging, left in queue: 800000\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.45\n",
            "Opening File...\n",
            "Start taggging, left in queue: 775008\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.46\n",
            "Opening File...\n",
            "Start taggging, left in queue: 750043\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.43\n",
            "Opening File...\n",
            "Start taggging, left in queue: 725122\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.5\n",
            "Opening File...\n",
            "Start taggging, left in queue: 700270\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.48\n",
            "Opening File...\n",
            "Start taggging, left in queue: 675496\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.48\n",
            "Opening File...\n",
            "Start taggging, left in queue: 650810\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.44\n",
            "Opening File...\n",
            "Start taggging, left in queue: 626209\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.48\n",
            "Opening File...\n",
            "Start taggging, left in queue: 601724\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.46\n",
            "Opening File...\n",
            "Start taggging, left in queue: 577368\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.45\n",
            "Opening File...\n",
            "Start taggging, left in queue: 553152\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.4\n",
            "Opening File...\n",
            "Start taggging, left in queue: 529095\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.45\n",
            "Opening File...\n",
            "Start taggging, left in queue: 505205\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.44\n",
            "Opening File...\n",
            "Start taggging, left in queue: 481494\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.5\n",
            "Opening File...\n",
            "Start taggging, left in queue: 457994\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.46\n",
            "Opening File...\n",
            "Start taggging, left in queue: 434662\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.4\n",
            "Opening File...\n",
            "Start taggging, left in queue: 411525\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.45\n",
            "Opening File...\n",
            "Start taggging, left in queue: 388597\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.48\n",
            "Opening File...\n",
            "Start taggging, left in queue: 365870\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.43\n",
            "Opening File...\n",
            "Start taggging, left in queue: 343344\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.47\n",
            "Opening File...\n",
            "Start taggging, left in queue: 321023\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.51\n",
            "Opening File...\n",
            "Start taggging, left in queue: 298941\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.42\n",
            "Opening File...\n",
            "Start taggging, left in queue: 277080\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.45\n",
            "Opening File...\n",
            "Start taggging, left in queue: 255453\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.43\n",
            "Opening File...\n",
            "Start taggging, left in queue: 234084\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.43\n",
            "Opening File...\n",
            "Start taggging, left in queue: 212958\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.47\n",
            "Opening File...\n",
            "Start taggging, left in queue: 192103\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.41\n",
            "Opening File...\n",
            "Start taggging, left in queue: 171496\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.47\n",
            "Opening File...\n",
            "Start taggging, left in queue: 151181\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.47\n",
            "Opening File...\n",
            "Start taggging, left in queue: 131155\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.48\n",
            "Opening File...\n",
            "Start taggging, left in queue: 111408\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.53\n",
            "Opening File...\n",
            "Start taggging, left in queue: 91955\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.49\n",
            "Opening File...\n",
            "Start taggging, left in queue: 72789\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.57\n",
            "Opening File...\n",
            "Start taggging, left in queue: 53931\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.57\n",
            "Opening File...\n",
            "Start taggging, left in queue: 35354\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            ":: At step 20000\n",
            "Saving File...\n",
            "Minutes: 5.56\n",
            "Opening File...\n",
            "Start taggging, left in queue: 17038\n",
            ":: At step 5000\n",
            ":: At step 10000\n",
            ":: At step 15000\n",
            "Saving File...\n",
            "Minutes: 3.78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvW6InFH1-09",
        "outputId": "3ae8d035-c24b-4ec1-e4ea-97f545000400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(len(progress_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "793164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrvwx1J3wruk"
      },
      "source": [
        "with open('progress_dict.pickle', 'rb') as handle:\n",
        "    progress_dict = pickle.load(handle) \n",
        "pos_sentences = []\n",
        "to_pos = df_all[\"words\"].to_list()\n",
        "for sent in to_pos:\n",
        "    pos_sentences.append(progress_dict[sent])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsMy9c3Nx2qT"
      },
      "source": [
        "df_all[\"pos\"] = pos_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHQj2eiix6Nu",
        "outputId": "69b9b050-88b2-41cb-8d4d-fbcd0372e558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df_all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>categories</th>\n",
              "      <th>is_which_set</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i figured betty crocker would make a great cake</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "      <td>PRON VERB ADJ NOUN AUX VERB DET ADJ NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i was offered the opportunity to taste this pr...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "      <td>PRON VERB VERB DET NOUN PART VERB DET NOUN ADP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>it is small and hard to depress when wearing f...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "      <td>PRON VERB ADJ CCONJ ADJ PART VERB ADV VERB ADJ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the grids do not remove but are easy to wipe d...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "      <td>DET NOUN VERB ADV VERB CCONJ VERB ADJ PART VER...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i mean no secret characters and you change you...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "      <td>PRON VERB DET ADJ NOUN CCONJ PRON VERB PRON NO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799995</th>\n",
              "      <td>the size is just right for a meal</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "      <td>DET NOUN VERB ADV ADJ ADP DET NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799996</th>\n",
              "      <td>clean up is a breeze due to the nice slick finish</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "      <td>VERB ADP VERB DET NOUN ADP ADP DET ADJ ADJ NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799997</th>\n",
              "      <td>unfortunately the initial mouse arrived missin...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "      <td>ADV DET ADJ NOUN VERB VERB DET NOUN PRON VERB ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799998</th>\n",
              "      <td>we have used this in the oven microwave safe f...</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "      <td>PRON VERB VERB DET ADP DET ADJ NOUN ADJ NOUN C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799999</th>\n",
              "      <td>if you are looking for a good heavy bag glove ...</td>\n",
              "      <td>0</td>\n",
              "      <td>test</td>\n",
              "      <td>ADP PRON VERB VERB ADP DET ADJ ADJ NOUN NOUN N...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    words  ...                                                pos\n",
              "0         i figured betty crocker would make a great cake  ...           PRON VERB ADJ NOUN AUX VERB DET ADJ NOUN\n",
              "1       i was offered the opportunity to taste this pr...  ...  PRON VERB VERB DET NOUN PART VERB DET NOUN ADP...\n",
              "2       it is small and hard to depress when wearing f...  ...  PRON VERB ADJ CCONJ ADJ PART VERB ADV VERB ADJ...\n",
              "3       the grids do not remove but are easy to wipe d...  ...  DET NOUN VERB ADV VERB CCONJ VERB ADJ PART VER...\n",
              "4       i mean no secret characters and you change you...  ...  PRON VERB DET ADJ NOUN CCONJ PRON VERB PRON NO...\n",
              "...                                                   ...  ...                                                ...\n",
              "799995                  the size is just right for a meal  ...                 DET NOUN VERB ADV ADJ ADP DET NOUN\n",
              "799996  clean up is a breeze due to the nice slick finish  ...    VERB ADP VERB DET NOUN ADP ADP DET ADJ ADJ NOUN\n",
              "799997  unfortunately the initial mouse arrived missin...  ...  ADV DET ADJ NOUN VERB VERB DET NOUN PRON VERB ...\n",
              "799998  we have used this in the oven microwave safe f...  ...  PRON VERB VERB DET ADP DET ADJ NOUN ADJ NOUN C...\n",
              "799999  if you are looking for a good heavy bag glove ...  ...  ADP PRON VERB VERB ADP DET ADJ ADJ NOUN NOUN N...\n",
              "\n",
              "[800000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzEKuHUb2UoT"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "df_all = shuffle(df_all)\n",
        "df_all.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttUAonyWRsMh",
        "outputId": "a01a0dd9-8625-4463-ed60-7a4a53a53db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from collections import Counter\n",
        "Counter(df_all[df_all[\"is_which_set\"]==\"test\"].categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 50000, 1: 50000})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj0Nj6_Eetr-"
      },
      "source": [
        "df_all.to_pickle('df_all.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufUb6zkhyW2r"
      },
      "source": [
        "df_all = pd.read_pickle('df_all.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tIcYLDDyaGq",
        "outputId": "197d5dc2-ce4b-47dc-ca0d-88310f495e86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "df_all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>categories</th>\n",
              "      <th>is_which_set</th>\n",
              "      <th>pos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in bought this when in bought the pop maker</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "      <td>ADP VERB DET ADV ADV VERB DET NOUN NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>as for pop embellishing well that wasn to too ...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "      <td>ADP ADP NOUN VERB INTJ DET VERB PART ADV ADJ P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>in do save the money and spend it instead on e...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "      <td>ADP VERB VERB DET NOUN CCONJ VERB PRON ADV ADP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>did not really care many of the cakes at all</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "      <td>VERB ADV ADV VERB ADJ ADP DET NOUN ADV ADV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>not up to normal standing for wilton yearbooks...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "      <td>ADV ADV ADP ADJ NOUN ADP NOUN NOUN ADP DET NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799995</th>\n",
              "      <td>as cases though it is not the best but it is c...</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "      <td>ADP NOUN ADP PRON VERB ADV DET ADJ CCONJ PRON ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799996</th>\n",
              "      <td>not as lot to complain about with this case at...</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "      <td>ADV ADV NOUN PART VERB ADP ADP DET NOUN ADP DE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799997</th>\n",
              "      <td>in was happy with the tpu case in bought for m...</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "      <td>ADP VERB ADJ ADP DET NOUN NOUN ADP VERB ADP PR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799998</th>\n",
              "      <td>it fits the phone perfectly the cut outs are a...</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "      <td>PRON VERB DET NOUN ADV DET NOUN NOUN VERB DET ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799999</th>\n",
              "      <td>volume is hard to control with the case on but...</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "      <td>NOUN VERB ADJ PART VERB ADP DET NOUN ADP CCONJ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>800000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    words  ...                                                pos\n",
              "0             in bought this when in bought the pop maker  ...            ADP VERB DET ADV ADV VERB DET NOUN NOUN\n",
              "1       as for pop embellishing well that wasn to too ...  ...  ADP ADP NOUN VERB INTJ DET VERB PART ADV ADJ P...\n",
              "2       in do save the money and spend it instead on e...  ...  ADP VERB VERB DET NOUN CCONJ VERB PRON ADV ADP...\n",
              "3            did not really care many of the cakes at all  ...         VERB ADV ADV VERB ADJ ADP DET NOUN ADV ADV\n",
              "4       not up to normal standing for wilton yearbooks...  ...    ADV ADV ADP ADJ NOUN ADP NOUN NOUN ADP DET NOUN\n",
              "...                                                   ...  ...                                                ...\n",
              "799995  as cases though it is not the best but it is c...  ...  ADP NOUN ADP PRON VERB ADV DET ADJ CCONJ PRON ...\n",
              "799996  not as lot to complain about with this case at...  ...  ADV ADV NOUN PART VERB ADP ADP DET NOUN ADP DE...\n",
              "799997  in was happy with the tpu case in bought for m...  ...  ADP VERB ADJ ADP DET NOUN NOUN ADP VERB ADP PR...\n",
              "799998  it fits the phone perfectly the cut outs are a...  ...  PRON VERB DET NOUN ADV DET NOUN NOUN VERB DET ...\n",
              "799999  volume is hard to control with the case on but...  ...  NOUN VERB ADJ PART VERB ADP DET NOUN ADP CCONJ...\n",
              "\n",
              "[800000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    }
  ]
}